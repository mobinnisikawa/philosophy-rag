import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from pypdf import PdfReader
import os, json

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="å“²å­¦RAGã‚·ã‚¹ãƒ†ãƒ ", layout="wide")
st.title("ğŸ“š å“²å­¦RAGã‚·ã‚¹ãƒ†ãƒ  (Streamlitç‰ˆ)")

# --- å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ« ---
HISTORY_FILE = "chat_history.json"

def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_history(history):
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

# å±¥æ­´èª­ã¿è¾¼ã¿
history = load_history()

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«å±¥æ­´è¡¨ç¤º ---
st.sidebar.header("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆå±¥æ­´")
if history:
    for h in history[-5:]:  # æœ€æ–°5ä»¶ã ã‘è¡¨ç¤º
        st.sidebar.write(f"Q: {h['question']}")
        st.sidebar.caption(f"A: {h['answer'][:80]}...")
    if st.sidebar.button("å…¨å±¥æ­´ã‚’è¡¨ç¤ºã™ã‚‹"):
        for h in history:
            st.sidebar.write(f"Q: {h['question']}")
            st.sidebar.caption(f"A: {h['answer'][:120]}...")
    st.sidebar.download_button(
        "å±¥æ­´ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (JSON)",
        data=json.dumps(history, ensure_ascii=False, indent=2),
        file_name="chat_history.json",
        mime="application/json"
    )
else:
    st.sidebar.info("ã¾ã å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")

# â­ å±¥æ­´ãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½
if st.sidebar.button("å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ"):
    history = []
    save_history(history)
    st.sidebar.success("å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸï¼")

# --- PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
uploaded_files = st.file_uploader(
    "PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ (è¤‡æ•°å¯)",
    type=["pdf"],
    accept_multiple_files=True
)

all_docs = []
if uploaded_files:
    for uploaded_file in uploaded_files:
        reader = PdfReader(uploaded_file)
        text = "".join(p.extract_text() or "" for p in reader.pages)
        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        docs = [Document(page_content=chunk, metadata={"source": uploaded_file.name})
                for chunk in splitter.split_text(text)]
        all_docs.extend(docs)
    st.success(f"âœ… å…¨PDFã®åˆè¨ˆãƒãƒ£ãƒ³ã‚¯æ•°: {len(all_docs)}")

# --- ãƒ™ã‚¯ãƒˆãƒ«DBä½œæˆ ---
if all_docs:
    emb = OpenAIEmbeddings(model="text-embedding-3-small")
    vs = FAISS.from_documents(all_docs, emb)
    retriever = vs.as_retriever(search_type="mmr", search_kwargs={"k": 8, "fetch_k": 20})

    # --- QAå…¥åŠ› ---
    query = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    if query:
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        docs = retriever.get_relevant_documents(query)
        context = "\n".join([d.page_content for d in docs])

        prompt = f"æ¬¡ã®è³‡æ–™ã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n\nè³‡æ–™:\n{context}\n\nè³ªå•: {query}\n\nç­”ãˆ:"
        answer = llm.predict(prompt)

        st.subheader("ğŸ“ å›ç­”")
        st.write(answer)

        # --- å±¥æ­´ã«ä¿å­˜ ---
        history.append({"question": query, "answer": answer})
        save_history(history)

        # --- é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¡¨ç¤º ---
        with st.expander("ğŸ“– å‚ç…§ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"):
            for d in docs:
                st.markdown(f"**{d.metadata['source']}**: {d.page_content[:200]}...")
