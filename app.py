
import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from pypdf import PdfReader
import os

st.set_page_config(page_title="å“²å­¦RAG", layout="wide")
st.title("ğŸ“š å“²å­¦RAGã‚·ã‚¹ãƒ†ãƒ  (Streamlitç‰ˆ)")

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["pdf"])
if uploaded_file:
    reader = PdfReader(uploaded_file)
    text = "\n".join([p.extract_text() or "" for p in reader.pages])
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = [Document(page_content=chunk, metadata={"source": uploaded_file.name})
            for chunk in splitter.split_text(text)]

    st.success(f"âœ… ãƒãƒ£ãƒ³ã‚¯æ•°: {len(docs)}")

    # ãƒ™ã‚¯ãƒˆãƒ«DBä½œæˆ
    emb = OpenAIEmbeddings(model="text-embedding-3-small")
    vs = FAISS.from_documents(docs, emb)
    retriever = vs.as_retriever(search_type="mmr", search_kwargs={"k":8, "fetch_k":20})

    # è³ªå•å…¥åŠ›
    question = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    if question:
        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        from langchain.chains import create_retrieval_chain
        from langchain.chains.combine_documents import create_stuff_documents_chain
        from langchain_core.prompts import ChatPromptTemplate

        SYSTEM_PROMPT = '''ã‚ãªãŸã¯å¤§å­¦é™¢ãƒ¬ãƒ™ãƒ«ã®å“²å­¦ç ”ç©¶æŒ‡å°è€…ã§ã™ã€‚
        ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPDFã‚’æ ¹æ‹ ã«ã€å­¦è¡“çš„ã«æ­£ç¢ºã‹ã¤é•·æ–‡ã§æ—¥æœ¬èªè§£èª¬ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
        '''
        prompt = ChatPromptTemplate.from_template("è³ªå•: {input}\n\n# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n{context}\n" + SYSTEM_PROMPT)

        doc_chain = create_stuff_documents_chain(llm, prompt)
        rag_chain = create_retrieval_chain(retriever, doc_chain)

        result = rag_chain.invoke({"input": question})
        st.write(result["answer"])
